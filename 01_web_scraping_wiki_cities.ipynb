{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h7XGRW58Onq4",
    "outputId": "06035ada-1ef2-4c65-a285-61994611f6aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /Users/subinjosethomas/opt/anaconda3/lib/python3.9/site-packages (4.11.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/subinjosethomas/opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4) (2.3.1)\n"
     ]
    }
   ],
   "source": [
    "# colab has an older version of beautifulsoup by default\n",
    "# here we upgrade it\n",
    "# if you are working on your own computer, you can probably comment this step out and skip it\n",
    "!pip install --upgrade beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "09E5mZ6mjM-J"
   },
   "outputs": [],
   "source": [
    "# 1. import libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EfulSS0rj9Gd"
   },
   "outputs": [],
   "source": [
    "# 2. find url and store it in a variable\n",
    "url = \"https://en.wikipedia.org/wiki/Berlin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ToaJ81GkC0r",
    "outputId": "4973d63e-4efe-4105-f8da-be2f6be04be5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. download html with a get request\n",
    "response = requests.get(url)\n",
    "response.status_code # 200 status code means OK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bBB9cK_1kHeK"
   },
   "outputs": [],
   "source": [
    "# 4.1. parse html (create the 'soup')\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "# 4.2. check that the html code looks like it should\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NEPylwtLkRz6",
    "outputId": "d14a65cd-517c-454a-8608-1c7f9a53c8a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1 class=\"firstHeading mw-first-heading\" id=\"firstHeading\"><span class=\"mw-page-title-main\">Berlin</span></h1>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. retrieve/extract the desired info (here, you'll paste the \"Selector\" you copied before to get the element that belongs to the top movie)\n",
    "\n",
    "# let's first try to get the name of the city\n",
    "# by copying the selector we can see that it has the id firstHeading (it also has a class by the same name!)\n",
    "soup.select(\"#firstHeading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "xC2gDSscWtyS",
    "outputId": "010a8325-7cc1-4b6f-f25f-64b7075c857c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Berlin'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"#firstHeading\")[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "zqaG8u2YX96Z",
    "outputId": "a4d6af80-fcf8-4ce1-bb67-dc85dd5b7ce9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Germany'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use this class, infobox-data, to target the information country\n",
    "soup.select(\".infobox-data\")[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdVBTcmTIwh8"
   },
   "outputs": [],
   "source": [
    "#soup.select(\".infobox-data\")[0].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5NbgdoeYKIo"
   },
   "source": [
    "Now we just carry on exploring the html, finding classes, ids, and selectors to target the information we need. Hopefully these classes and selectors will be universal across all cities on wikipedia, but it is likely that they will change in a few places, and we will have to try to make our code robust to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "6ZaT16qaP2yJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sv/djrh3svn0hl9fv9d7jw8xwl40000gn/T/ipykernel_46407/4234743330.py:29: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  response_dict['population'] = soup.select_one('th.infobox-header:-soup-contains(\"Population\")').parent.find_next_sibling().find(text=re.compile(r'\\d+'))\n",
      "/var/folders/sv/djrh3svn0hl9fv9d7jw8xwl40000gn/T/ipykernel_46407/4234743330.py:29: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  response_dict['population'] = soup.select_one('th.infobox-header:-soup-contains(\"Population\")').parent.find_next_sibling().find(text=re.compile(r'\\d+'))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0638</td>\n",
       "      <td>8.4056</td>\n",
       "      <td>759224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>Germany</td>\n",
       "      <td>52.3112</td>\n",
       "      <td>13.2418</td>\n",
       "      <td>3677472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cologne</td>\n",
       "      <td>Germany</td>\n",
       "      <td>50.5611</td>\n",
       "      <td>6.5710</td>\n",
       "      <td>1073096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Munich</td>\n",
       "      <td>Germany</td>\n",
       "      <td>48.0815</td>\n",
       "      <td>11.3430</td>\n",
       "      <td>1487708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hamburg</td>\n",
       "      <td>Germany</td>\n",
       "      <td>53.3300</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>1906411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        city  country  latitude  longitude  population\n",
       "0  Frankfurt  Germany   50.0638     8.4056      759224\n",
       "1     Berlin  Germany   52.3112    13.2418     3677472\n",
       "2    Cologne  Germany   50.5611     6.5710     1073096\n",
       "3     Munich  Germany   48.0815    11.3430     1487708\n",
       "4    Hamburg  Germany   53.3300    10.0000     1906411"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recreate_wiki(cities):\n",
    "  # empty list that will be filled with one dictionary of information per city\n",
    "  list_for_df = []\n",
    "  \n",
    "  # begin a for loop to create a dictionary of information for each city\n",
    "  for city in cities:\n",
    "    # we can use the universal nature of wikipedias urls to our advantage here\n",
    "    # all of the urls are the same besides the city name\n",
    "    url = f'https://en.wikipedia.org/wiki/{city}'\n",
    "\n",
    "    # here we make our soup for the city\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "    # here we initialise our empty dictionary for the city\n",
    "    response_dict = {}\n",
    "\n",
    "    # here we fill the dictionary with information using the ids, classes, and selectors that we found in the html\n",
    "    response_dict['city'] = soup.select(\".firstHeading\")[0].get_text()\n",
    "    response_dict['country'] = soup.select(\".infobox-data\")[0].get_text()\n",
    "    response_dict['latitude'] = soup.select(\".latitude\")[0].get_text()\n",
    "    response_dict['longitude'] = soup.select(\".longitude\")[0].get_text()\n",
    "    # not all of the wikipedia pages contain elevation, look at Hamburg\n",
    "    # the if clause means that our code can continue and won't stop at this hurdle\n",
    "    if soup.select_one('.infobox-label:-soup-contains(\"Elevation\")'):\n",
    "      response_dict['elevation'] = soup.select_one('.infobox-label:-soup-contains(\"Elevation\")').find_next(class_='infobox-data').get_text()\n",
    "    response_dict['website'] = soup.select_one('.infobox-label:-soup-contains(\"Website\")').find_next(class_='infobox-data').get_text()\n",
    "    if soup.select_one('th.infobox-header:-soup-contains(\"Population\")'):\n",
    "        response_dict['population'] = soup.select_one('th.infobox-header:-soup-contains(\"Population\")').parent.find_next_sibling().find(text=re.compile(r'\\d+'))\n",
    "    \n",
    "    # add our dictionary for the city to list_for_df\n",
    "    list_for_df.append(response_dict)\n",
    "  \n",
    "  # make the DataFrame\n",
    "  cities_df = pd.DataFrame(list_for_df)\n",
    "\n",
    "  # fixing latitude\n",
    "  cities_df['latitude'] = cities_df['latitude'].str.split('″').str[0].str.replace('°', '.', regex=False).str.replace('′', '', regex=False).str.replace('N', '', regex=False)\n",
    "  # fixing longitude\n",
    "  cities_df['longitude'] = cities_df['longitude'].str.split('″').str[0].str.replace('°', '.', regex=False).str.replace('′', '', regex=False).str.replace('E', '', regex=False)\n",
    "  # fixing elevation\n",
    "  cities_df.insert(4, 'elevation_in_meters', cities_df['elevation'].str.split('m').str[0].str.strip())\n",
    "  cities_df['population'] = cities_df['population'].str.replace(',', '', regex=False)\n",
    "\n",
    "  # return the DataFrame\n",
    "  return cities_df\n",
    "\n",
    "list_of_cities = ['Berlin', 'Hamburg', 'London', 'Manchester', 'Barcelona']\n",
    "cities = recreate_wiki(list_of_cities)\n",
    "list_of_cities = ['Frankfurt', 'Berlin', 'Cologne', 'Munich', 'Hamburg']\n",
    "cities = recreate_wiki(list_of_cities)\n",
    "cities_data = cities[['city','country','latitude','longitude','population']]\n",
    "cities_e_bike = cities_data.copy() \n",
    "cities_e_bike['latitude'] = cities_e_bike['latitude'].astype(float)\n",
    "cities_e_bike['longitude'] = cities_e_bike['longitude'].astype(float)\n",
    "cities_e_bike['population'] = pd.to_numeric(cities_e_bike['population'],errors='coerce')\n",
    "cities_e_bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
